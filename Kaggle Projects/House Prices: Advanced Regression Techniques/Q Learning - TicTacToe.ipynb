{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        self.states=[]\n",
    "        self.action=[]\n",
    "        \n",
    "        self.visited_states=0\n",
    "        \n",
    "        self.environment=np.zeros((3,3),dtype=str)\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                self.environment[i][j]=\"_\"\n",
    "                \n",
    "    def printBoard(self):\n",
    "        \n",
    "        for i in range(3):\n",
    "            print(\"|\",end=\"\")\n",
    "            \n",
    "            for j in range(3):\n",
    "                print(self.environment[i][j],end=\"\")\n",
    "                print(\"|\",end=\"\")\n",
    "                \n",
    "            print(\"\")\n",
    "    \n",
    "    def getIndex(self,state):\n",
    "        \n",
    "        \n",
    "        for i in range(len(self.states)):\n",
    "            if np.array_equal(self.states[i],state):\n",
    "                return i\n",
    "            \n",
    "        return None\n",
    "        \n",
    "    \n",
    "    def visited(self,state):\n",
    "        \n",
    "        for i in range(len(self.states)):\n",
    "            if np.array_equal(self.states[i],state):\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "                \n",
    "                \n",
    "    def availableMoves(self):\n",
    "        list=[]\n",
    "        \n",
    "        for i in range(3):\n",
    "            \n",
    "            for j in range(3):\n",
    "                if self.environment[i][j]==\"_\":\n",
    "                    list.append(i*3+j)\n",
    "                    \n",
    "        return list\n",
    "    \n",
    "    \n",
    "    def detectWinner(self,player):\n",
    "        \n",
    "        if player==\"O\":\n",
    "            \n",
    "            for i in range(3):\n",
    "                if np.array_equal(self.environment[i],['O', 'O', 'O']) or np.array_equal(self.environment[:,i],['O', 'O', 'O']):\n",
    "                    return True\n",
    "                \n",
    "                \n",
    "            if np.array_equal(ttt.environment.diagonal(),['O', 'O', 'O']) or np.array_equal(np.fliplr(ttt.environment).diagonal(),['O', 'O', 'O']):\n",
    "                return True\n",
    "        \n",
    "        \n",
    "        if player==\"X\":\n",
    "            \n",
    "            for i in range(3):\n",
    "                if np.array_equal(self.environment[i],['X', 'X', 'X']) or np.array_equal(self.environment[:,i],['X', 'X', 'X']):\n",
    "                    return True\n",
    "                \n",
    "                \n",
    "            if np.array_equal(ttt.environment.diagonal(),['X', 'X', 'X']) or np.array_equal(np.fliplr(ttt.environment).diagonal(),['X', 'X', 'X']):\n",
    "                return True    \n",
    "        \n",
    "        \n",
    "        \n",
    "        return False\n",
    "                \n",
    "                \n",
    "    \n",
    "    def placeX(self,index):\n",
    "        \n",
    "        x=int(index/3)\n",
    "        y=index%3 \n",
    "        self.environment[x][y]=\"X\"                    \n",
    "    \n",
    "    def placeO(self,index):\n",
    "        \n",
    "        x=int(index/3)\n",
    "        y=index%3 \n",
    "        self.environment[x][y]=\"O\" \n",
    "        \n",
    "    def clearGame(self):\n",
    "        \n",
    "        self.environment=np.zeros((3,3),dtype=str)\n",
    "        \n",
    "        for i in range(3):\n",
    "            for j in range(3):\n",
    "                self.environment[i][j]=\"_\"\n",
    "        \n",
    "        \n",
    "        \n",
    "    def playGame(self):\n",
    "        \n",
    "        turn=random.sample([1,2],1)[0]\n",
    "        \n",
    "        #print(turn)\n",
    "        \"\"\"\n",
    "        self.printBoard()\n",
    "        \"\"\"\n",
    "        \n",
    "        if not (self.visited(np.array(self.environment, copy=True))):\n",
    "                self.states.append(np.array(self.environment, copy=True))\n",
    "                self.action.append(np.zeros(9))\n",
    "                self.visited_states=self.visited_states+1\n",
    "                \n",
    "        \n",
    "        \n",
    "        while(1):\n",
    "            \n",
    "            \n",
    "            if len(self.availableMoves())==0:\n",
    "                #print(\"\")\n",
    "                #print(\"Game Over: Tie Game\")\n",
    "                break\n",
    "            #print(\"\")\n",
    "            \"\"\"\n",
    "            print(\"Please Enter Move from {} , or q to quit\".format(self.availableMoves()))\n",
    "            move=input()\n",
    "            \n",
    "            \n",
    "            \n",
    "            if move=='q':\n",
    "                break\n",
    "            else:\n",
    "                move=int(move)\n",
    "            \"\"\"\n",
    "            \n",
    "            move=random.sample(self.availableMoves(),  1)[0]\n",
    "            \n",
    "            if turn%2==0:\n",
    "                self.getIndex()\n",
    "                self.placeX(move)\n",
    "                \n",
    "            else:\n",
    "                self.placeO(move)\n",
    "            \n",
    "            \n",
    "            #print(\"\")\n",
    "            \"\"\"\n",
    "            self.printBoard()\n",
    "            \n",
    "            \n",
    "            \"\"\"\n",
    "            \n",
    "            self.visited_states=self.visited_states+1\n",
    "            if self.getIndex(np.array(self.environment, copy=True))==None:\n",
    "                self.states.append(np.array(self.environment, copy=True))\n",
    "                self.action.append(np.zeros(9))\n",
    "                \n",
    "                \n",
    "            if self.detectWinner(\"O\"):\n",
    "                #print(\"\")\n",
    "                #print(\"O has Won!!\")\n",
    "                break\n",
    "            \n",
    "            if self.detectWinner(\"X\"):\n",
    "                #print(\"\")\n",
    "                #print(\"X has Won!!\")\n",
    "                break\n",
    "                \n",
    "           \n",
    "            turn=turn+1\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "            \n",
    "    def reward(self):\n",
    "        \n",
    "        if self.detectWinner(\"O\"):\n",
    "             reward=-100\n",
    "                    \n",
    "        elif self.detectWinner(\"X\"):\n",
    "            reward=100\n",
    "\n",
    "                    \n",
    "        elif len(self.availableMoves())==0:\n",
    "            reward=10\n",
    "    \n",
    "        else:       \n",
    "            reward=0\n",
    "            \n",
    "        return reward\n",
    "        \n",
    "    def playAgainstTrainedAgent(self):\n",
    "        \n",
    "        self.clearGame()\n",
    "        turn=random.sample([1,2],1)[0]\n",
    "        \n",
    "        self.printBoard()\n",
    "        print(\"\")\n",
    "        while(1):\n",
    "            \n",
    "            if turn%2==0:\n",
    "                index=self.getIndex(np.array(self.environment, copy=True))\n",
    "                \n",
    "                if index==None:\n",
    "                    move=random.sample(self.availableMoves(),1)[0]\n",
    "                else:\n",
    "                    print(\"\")\n",
    "                    print(\"Q-Values from this state: {}\".format(self.action[index]))\n",
    "                    print(\"\")\n",
    "                    if np.array_equal(self.action[index],np.zeros(9)):\n",
    "                        move=random.sample(self.availableMoves(),1)[0]\n",
    "                    else:\n",
    "                        \n",
    "                        available=self.availableMoves()\n",
    "                        max_action=max(self.action[index])\n",
    "                        \n",
    "                        for i in range(len((self.action[index]))):\n",
    "                            \n",
    "                            if self.action[index][i]==max_action and (i in available):\n",
    "                                move=i\n",
    "                    \n",
    "                self.placeX(move)\n",
    "                \n",
    "            else:\n",
    "                move=int(input(\"Pick Available Moves {}\".format(self.availableMoves())))\n",
    "                self.placeO(move)\n",
    "                \n",
    "            self.printBoard()\n",
    "            print(\"\")\n",
    "            if len(self.availableMoves())==0:\n",
    "                print(\"\")\n",
    "                print(\"Game Over: Tie Game\")\n",
    "                break  \n",
    "                \n",
    "            if self.detectWinner(\"O\"):\n",
    "                print(\"\")\n",
    "                print(\"O has Won!!\")\n",
    "                break\n",
    "            \n",
    "            if self.detectWinner(\"X\"):\n",
    "                print(\"\")\n",
    "                print(\"X has Won!!\")\n",
    "                break\n",
    "            turn=turn+1\n",
    "        \n",
    "            \n",
    "    def QLearning(self,learning_rate,discount_factor,iterations):\n",
    "        \n",
    "        episode=0\n",
    "        \n",
    "        while episode<iterations:\n",
    "    \n",
    "            if episode%1000==0:\n",
    "                print(\"Episode {}\".format(episode))\n",
    "                \n",
    "            self.clearGame()\n",
    "            start=random.sample([1,2],1)[0]\n",
    "            \n",
    "            \n",
    "            if start%2!=0:\n",
    "                \n",
    "                opponentMove=random.sample(self.availableMoves(),1)[0]\n",
    "                self.placeO(opponentMove)\n",
    "                    \n",
    "            while(1):\n",
    "                \n",
    "                t0=self.getIndex(np.array(self.environment, copy=True))\n",
    "                \n",
    "                if t0==None:\n",
    "                    self.states.append(np.array(self.environment, copy=True))\n",
    "                    self.action.append(np.zeros(9))\n",
    "                    t0=self.getIndex(np.array(self.environment, copy=True))\n",
    "                \n",
    "                \n",
    "                move=random.sample(self.availableMoves(),1)[0]\n",
    "                self.placeX(move)\n",
    "                \n",
    "                reward=self.reward()\n",
    "                \n",
    "                if reward==100:\n",
    "                    \n",
    "                    t1=self.getIndex(np.array(self.environment, copy=True))\n",
    "            \n",
    "                    if t1==None:\n",
    "                        self.states.append(np.array(self.environment, copy=True))\n",
    "                        self.action.append(np.zeros(9))\n",
    "                        t1=self.getIndex(np.array(self.environment, copy=True))\n",
    "            \n",
    "                    self.action[t0][move]=(1-learning_rate)*self.action[t0][move]+learning_rate*(reward+discount_factor*max(self.action[t1])-self.action[t0][move])\n",
    "                    break\n",
    "                \n",
    "                elif len(self.availableMoves())==0:\n",
    "                    \n",
    "                    t1=self.getIndex(np.array(self.environment, copy=True))\n",
    "            \n",
    "                    if t1==None:\n",
    "                        self.states.append(np.array(self.environment, copy=True))\n",
    "                        self.action.append(np.zeros(9))\n",
    "                        t1=self.getIndex(np.array(self.environment, copy=True))\n",
    "            \n",
    "                    self.action[t0][move]=(1-learning_rate)*self.action[t0][move]+learning_rate*(reward+discount_factor*max(self.action[t1])-self.action[t0][move])\n",
    "                    \n",
    "                    break\n",
    "                  \n",
    "                \n",
    "                else:\n",
    "                    opponentMove=random.sample(self.availableMoves(),1)[0]\n",
    "                    self.placeO(opponentMove)\n",
    "                    \n",
    "                    t1=self.getIndex(np.array(self.environment, copy=True))\n",
    "            \n",
    "                    if t1==None:\n",
    "                        self.states.append(np.array(self.environment, copy=True))\n",
    "                        self.action.append(np.zeros(9))\n",
    "                        t1=self.getIndex(np.array(self.environment, copy=True))\n",
    "                    \n",
    "                    reward=self.reward()\n",
    "                    self.action[t0][move]=(1-learning_rate)*self.action[t0][move]+learning_rate*(reward+discount_factor*max(self.action[t1])-self.action[t0][move])\n",
    "                    \n",
    "                    if reward==-100 or len(self.availableMoves())==0:\n",
    "                        break\n",
    "                    \n",
    "            episode=episode+1\n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0\n",
      "Episode 1000\n",
      "Episode 2000\n",
      "Episode 3000\n",
      "Episode 4000\n",
      "Episode 5000\n",
      "Episode 6000\n",
      "Episode 7000\n",
      "Episode 8000\n",
      "Episode 9000\n",
      "Episode 10000\n",
      "Episode 11000\n",
      "Episode 12000\n",
      "Episode 13000\n",
      "Episode 14000\n",
      "Episode 15000\n",
      "Episode 16000\n",
      "Episode 17000\n",
      "Episode 18000\n",
      "Episode 19000\n",
      "Episode 20000\n",
      "Episode 21000\n",
      "Episode 22000\n",
      "Episode 23000\n",
      "Episode 24000\n",
      "Episode 25000\n",
      "Episode 26000\n",
      "Episode 27000\n",
      "Episode 28000\n",
      "Episode 29000\n",
      "Episode 30000\n",
      "Episode 31000\n",
      "Episode 32000\n",
      "Episode 33000\n",
      "Episode 34000\n",
      "Episode 35000\n",
      "Episode 36000\n",
      "Episode 37000\n",
      "Episode 38000\n",
      "Episode 39000\n",
      "Episode 40000\n",
      "Episode 41000\n",
      "Episode 42000\n",
      "Episode 43000\n",
      "Episode 44000\n",
      "Episode 45000\n",
      "Episode 46000\n",
      "Episode 47000\n",
      "Episode 48000\n",
      "Episode 49000\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "ttt=TicTacToe()\n",
    "\n",
    "ttt.QLearning(0.75,0.75,50000)\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6436"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ttt.action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['X' 'O' 'X']\n",
      " ['X' '_' 'O']\n",
      " ['O' '_' '_']]\n",
      "[ 0.          0.          0.          0.          8.43750075  0.\n",
      "  0.          1.93505287 16.66067977]\n"
     ]
    }
   ],
   "source": [
    "print(ttt.states[3])\n",
    "print(ttt.action[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|_|_|_|\n",
      "|_|_|_|\n",
      "|_|_|_|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ttt.playAgainstTrainedAgent()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
